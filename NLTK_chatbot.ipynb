{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By0HztXPO5py"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading the corpus of text"
      ],
      "metadata": {
        "id": "B62AFeGoPE3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('/content/data.txt','r',errors='ignore')\n",
        "raw_doc=f.read()"
      ],
      "metadata": {
        "id": "akCKBqssPEF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_doc=raw_doc.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP1DLf4OP_So",
        "outputId": "d8b598b6-6f21-43e1-9207-744ede9e7cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens=nltk.sent_tokenize(raw_doc)\n",
        "word_tokens=nltk.word_tokenize(raw_doc)"
      ],
      "metadata": {
        "id": "fz6p1Uq-QifR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "after tokenization"
      ],
      "metadata": {
        "id": "ckGjiwK4Swjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb9lBhkeRKbd",
        "outputId": "c4445ff1-ed6e-43a9-c7be-9f4a078461da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nmain menu\\n\\nwikipediathe free encyclopedia\\nsearch\\ncreate account\\nlog in\\n\\npersonal tools\\n\\nwiki loves monuments: photograph a monument, help wikipedia and win!',\n",
              " 'learn more\\n\\ntoggle the table of contents\\nchatbot\\n\\narticle\\ntalk\\nread\\nview source\\nview history\\n\\ntools\\npage semi-protected\\nfrom wikipedia, the free encyclopedia\\nfor other uses, see chatbot (disambiguation).',\n",
              " 'parts of this article (those related to everything, particularly sections after the intro) need to be updated.',\n",
              " 'the reason given is: this article is using citations from 1970 and virtually all claims about conversational capabilities are at least ten years out of date (for example the turing test was arguably made obsolete years ago by transformer models).',\n",
              " 'please help update this article to reflect recent events or newly available information.']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBn-0nxORcIY",
        "outputId": "09d584eb-e574-48ab-e001-69518985b0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['main', 'menu']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "performing text-preprocessing steps"
      ],
      "metadata": {
        "id": "Nv5dDVRqS8qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer=nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punc_dict=dict((ord(punct),None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))"
      ],
      "metadata": {
        "id": "rpqoggKVR4xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greeting function"
      ],
      "metadata": {
        "id": "7vMtu2_gUxDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greet_inputs=('hello','Hi','whats up','how are you?')\n",
        "greet_responses=('hi','hey','hey there')\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in greet_inputs:\n",
        "      return random.choice(greet_responses)"
      ],
      "metadata": {
        "id": "U2rynNL7UAcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "responses genrated by bot"
      ],
      "metadata": {
        "id": "WV3d6qZrVT2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "XXTs9g2FVS1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
        "  tfidf=TfidVec.fit_transform(sentence_tokens)\n",
        "  vals=cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat=vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf=flat[-2]\n",
        "  if req_tfidf==0:\n",
        "    robo1_response=robo1_response+\"I am sorry.  unable to understand\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response=robo1_response+sentence_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "GY4i2caIVld6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "defining chatflow"
      ],
      "metadata": {
        "id": "pSDS2s5aXU-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "print(\"Hello! I am learning bot. start typing.\")\n",
        "while(flag==True):\n",
        "  user_response=input()\n",
        "  user_response=user_response.lower()\n",
        "  if(user_response!='bye'):\n",
        "    if(user_response=='thank you'):\n",
        "      flag=False\n",
        "      print('Bot: you are welcome')\n",
        "    else:\n",
        "      if(greet(user_response)!=None):\n",
        "        print('Bot:'+greet(user_response))\n",
        "      else:\n",
        "        sentence_tokens.append(user_response)\n",
        "        word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "        final_words=list(set(word_tokens))\n",
        "        print('Bot: ',end=' ')\n",
        "        print(response(user_response))\n",
        "        sentence_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag=False\n",
        "    print('Bot: Goodbye')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP7Uhp_rXNak",
        "outputId": "f6b55ea1-7097-471f-95e1-d588bbd53962"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I am learning bot. start typing.\n",
            "aerospace engineering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot:  other branches of engineering\n",
            "aerospace engineering\n",
            "main article: aerospace engineering\n",
            "\n",
            "the insight lander with solar panels deployed in a cleanroom\n",
            "aerospace engineering covers the design, development, manufacture and operational behaviour of aircraft, satellites and rockets.\n",
            "engineering meaning\n",
            "Bot:  the term engineering is derived from the latin ingenium, meaning \"cleverness\" and ingeniare, meaning \"to contrive, devise\".\n",
            "computer science\n",
            "Bot:  computer engineering\n",
            "main article: computer engineering\n",
            "computer engineering (ce) is a branch of engineering that integrates several fields of computer science and electronic engineering required to develop computer hardware and software.\n",
            "cse means\n",
            "Bot:  [88] though physics and engineering are interrelated, it does not mean that a physicist is trained to do an engineer's job.\n",
            "thanks\n",
            "Bot:  I am sorry.  unable to understand\n",
            "thank you\n",
            "Bot: you are welcome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "7pZXZJeOZBcv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}